<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NLP With DL | Sanjeev Ram</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="NLP With DL" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="(Ever) learning to help machines understand language and pictures." />
<meta property="og:description" content="(Ever) learning to help machines understand language and pictures." />
<link rel="canonical" href="https://sanjeevr5.github.io/blog/NLP%20With%20DL/" />
<meta property="og:url" content="https://sanjeevr5.github.io/blog/NLP%20With%20DL/" />
<meta property="og:site_name" content="Sanjeev Ram" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="NLP With DL" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"(Ever) learning to help machines understand language and pictures.","headline":"NLP With DL","url":"https://sanjeevr5.github.io/blog/NLP%20With%20DL/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sanjeevr5.github.io/blog/feed.xml" title="Sanjeev Ram" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Sanjeev Ram</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/NLP%20With%20DL/">NLP With DL</a><a class="page-link" href="/blog/about/">Photography</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">NLP With DL</h1>
  </header>

  <div class="post-content">
    <h1 id="nlp-with-pytorch">NLP with Pytorch</h1>

<h2 id="1-binary-classification-problem-using-rnns"><a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_1.ipynb">1. Binary classification problem using RNNs</a></h2>

<p><strong>This exercise is performed on IMDB movie reviews dataset. There are two sentiments here 0. Negative 1. Positive.</strong>
<em>Techniques used</em></p>

<ol>
  <li>We shall train our embedding representations.</li>
  <li>Using an RNN architecture with pad_sequences, pack_pad_sequences and pad_packed_sequences.</li>
  <li>Dataloaders to have generator kind of data feed to the model.</li>
  <li>The sequences should not be too long. There should be a clipping factor and hence choose the vocabulary wisely.LSTMs cannot handle very long input sequence.</li>
  <li>Passing outputs of output layer or the hidden state to the dense layer.</li>
</ol>

<h2 id="2-multiclass-classification-with-rnns">2. <a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_2.ipynb">Multiclass classification with RNNs</a></h2>

<p>This exercise is performed on AGNews dataset with four news categories:</p>

<p>1 : World
2 : Sports
3 : Business
4 : Sci/Tec</p>

<p><em>Techniques used</em></p>

<ol>
  <li>We shall use bpeMB word representations as word vectors. This is a sub word tokenization process with a vector for every sub token. Sub-word tokens can make the sentences longer and hence to be used with care.</li>
  <li>We will just use the titles to predict the news category.</li>
  <li>This RNN architecture does not pad sequences, we shall feed the packed sequences directly to the embedding layer.</li>
  <li>Dataloaders to have generator kind of data feed to the model.</li>
  <li>Passing outputs of output layer or the hidden state to the dense layer.</li>
</ol>

<h2 id="3-a-multiclass-classification-using-the-embedding-bag-layer"><a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_3.ipynb">3. A multiclass classification using the Embedding bag layer</a></h2>

<p>The Embedding layer gives us a vector representation for every token while the embeddingbg performs an aggregation operation on top of every sentence and returns the result.</p>

<p>Embedding I/P : [[‘hi’, how’, ‘are’, ‘you’], [‘ok’, ‘bye’, ‘<pad>', '<pad>']]</pad></pad></p>

<p>Embedding layer O/P : (2,4,64)</p>

<p>Embedding bag I/P : [‘hi’, how’, ‘are’, ‘you’, ‘ok’, ‘bye’]</p>

<p>Embedding bag O/ P: There is no need of padding tokens it can be directly fed. (2, 64) -&gt; (B, embed_dim)</p>

<p>Embedding bag since it performs some aggregate operation sequential information is lost. There is no need of padding. Offsets should be mentioned instead of the padding. The offsets of above example is [0, 4] since first sentence starts from 0 and second sentence starts at 4th index.</p>

<h2 id="4-football-name-generator-with-char-rnn"><a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_5.ipynb">4. Football name generator with char RNN</a></h2>

<ol>
  <li>Without conditional generation - <strong>implemented</strong></li>
  <li>With conditional generation – <strong>yet to implement</strong></li>
</ol>

<h2 id="5-classification-with-ulmfit-awd-lstm-and-fastai"><a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/DL_With_NLP_ULMFiT_LM.ipynb">5. Classification with ULMFiT (AWD-LSTM) and fastai</a></h2>

<h2 id="6-distributed-pytorch-learning-on-ms-azure-platform---multiclass-classification"><a href="https://github.com/sanjeevr5/NLP_Excercises/blob/main/Distributed_Training_DL.ipynb">6. Distributed Pytorch learning on MS Azure Platform - Multiclass classification</a></h2>

<ol>
  <li>This activity is performed on AG News dataset. There are 4 labels.</li>
  <li>2D Max Pooling layer is used as the feeder layer for the SOFTMAX layer.</li>
  <li>Very fast to train and showing decent results for just 2 epochs and the size of the network is small compared to the above representations.</li>
  <li>Uses Azure Machine Learning with compute clusters for distributed training.</li>
  <li>**Uses Service Principal Mechanism for authentication and docker containers for training</li>
</ol>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>(Ever) learning to help machines understand language and pictures.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sanjeevr5" target="_blank" title="sanjeevr5"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
